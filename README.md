# Data-Scraping
Weather data scraping
# Introduction
Through this task, I  aim to extract data from websites to gather information about the weather of a given location. By using Python and accessing its web scraping libraries, we can automate data collection from multiple sources, saving time and effort in manual data collection.
# Tools & Approach
1. Programming language: Python <br>
2. I started by choosing a website for extracting information. I found that Google gets results from weather.com for showing weather results. Thus I decided to take the Google link of weather query as my primary website.<br>
3. The location is entered by the user.<br>
4. Python library: requests_html: The requests_html  library is a Python library specifically designed for web scraping and HTML parsing. It is built on top of requests and provides additional functionalities for handling HTML content. <br>
5. HTMLSessions: It is a class under the requests_html library.  HTMLSession is a class that provides a convenient way to make HTTP requests and interact with HTML content. It extends the functionality of the requests library by incorporating a built-in HTML parsing engine. <br>
6. The find() method is used to extract elements from the HTML using CSS selectors. <br>
7. .html is an extension that is used to read the code of HTML pages.<br>
8. In order to store the data, I tried using sqlite library.
# Conclusion
Through this task I got a hands on experience of using python for web scraping. I came across many useful libraries like requests_html, BeautifulSoup, Sqlite etc, and was able make best possible choice to complete the task. I encountered many deadends, but was dedicated to work to my full potential. The project provided an excellent opportunity for me to acquire a wealth of knowledge and learn a multitude of things.
